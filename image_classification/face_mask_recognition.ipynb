{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face-mask-recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUncoyTZCBnS"
      },
      "source": [
        "Dataset is downloaded from https://github.com/chandrikadeb7/Face-Mask-Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHbsrl4I98xW"
      },
      "source": [
        "# IMPORT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C_lRHhvYwqh",
        "outputId": "04c7ee04-cc26-4969-8f09-26de3def6ced"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVtgOi5L9m4O"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "from tensorflow.keras import datasets\n",
        "from utils.model import AugLayer, VGG, EfficientNetB0, CheckpointCallback, CustomLRDecay, plot_history\n",
        "\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Flatten, Add\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, AveragePooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Vl2UZU9k1C"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X49kZeQv-ACZ"
      },
      "source": [
        "# GET DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBMc5kNq-wym"
      },
      "source": [
        "PATH_DATASET = 'drive/My Drive/Colab Notebooks/face-mask-recognition/dataset/'\n",
        "PATH_DATASET_NEG = 'drive/My Drive/Colab Notebooks/face-mask-recognition/dataset/0/'\n",
        "PATH_DATASET_POS = 'drive/My Drive/Colab Notebooks/face-mask-recognition/dataset/1/'\n",
        "MIN_PIXEL = 32\n",
        "IMAGE_SIZE = (112, 112)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4XDj61D96Sa"
      },
      "source": [
        "# images = []\n",
        "# label = []\n",
        "# for name in os.listdir(PATH_DATASET_POS):\n",
        "#   img = Image.open(PATH_DATASET_POS+name)\n",
        "#   if (img.size[0] >= MIN_PIXEL) and (img.size[1] >= MIN_PIXEL):\n",
        "#     img = img.resize(IMAGE_SIZE, Image.LANCZOS)\n",
        "#     img = np.asarray(img)\n",
        "#     if img.shape == (*IMAGE_SIZE, 3):\n",
        "#       images.append(img)\n",
        "#       label.append(1)\n",
        "#     else: print(img.shape)\n",
        "#   else: print(img.size)\n",
        "\n",
        "# for name in os.listdir(PATH_DATASET_NEG):\n",
        "#   img = Image.open(PATH_DATASET_NEG+name)\n",
        "#   if (img.size[0] >= MIN_PIXEL) and (img.size[1] >= MIN_PIXEL):\n",
        "#     img = img.resize(IMAGE_SIZE, Image.LANCZOS)\n",
        "#     img = np.asarray(img)\n",
        "#     if img.shape == (*IMAGE_SIZE, 3):\n",
        "#       images.append(img)\n",
        "#       label.append(0)\n",
        "#     else: print(img.shape)\n",
        "#   else: print(img.size)\n",
        "\n",
        "# images = np.array(images)\n",
        "# label = np.array(label)\n",
        "\n",
        "# np.save(PATH_DATASET+'images.npy', images)\n",
        "# np.save(PATH_DATASET+'label.npy', label)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb3P_BBZALHf"
      },
      "source": [
        "images = np.load(PATH_DATASET+'images.npy')\n",
        "label = np.load(PATH_DATASET+'label.npy')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ub0OIe_-BMs"
      },
      "source": [
        "# https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, label, test_size=0.2, stratify=label, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, stratify=y_train, random_state=42) # 0.25 x 0.8 = 0.2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9yYDuCf-y2t"
      },
      "source": [
        "# TRAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL5ZBCl38uWk"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "EPOCHS = 30\n",
        "PATH_CHECKPOINT = './face-mask-recognition/checkpoint'\n",
        "PATH_CSV = './face-mask-recognition/training.log'\n",
        "LR_PROFILE = [0.1, 0.01, 0.001]\n",
        "LR_EPOCHS = [10, 20, EPOCHS]\n",
        "\n",
        "AUG_RESIZE= None # (128,128)\n",
        "AUG_CONTRAST = 0.10\n",
        "AUG_CROP = None\n",
        "AUG_FLIP = 'horizontal'\n",
        "AUG_ROT = 30.\n",
        "AUG_TRANSLATION = (0.10, 0.10)\n",
        "AUG_ZOOM = 0.10\n",
        "\n",
        "shutil.rmtree(PATH_CHECKPOINT, ignore_errors=True)\n",
        "os.makedirs(PATH_CHECKPOINT)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjQ1t8XX3vYf",
        "outputId": "c3e76ca1-0aae-4b4c-e7d6-505732d0be6f"
      },
      "source": [
        "aug_layer = AugLayer(AUG_RESIZE, None, AUG_CONTRAST,\n",
        "                     AUG_CROP, AUG_FLIP, AUG_ROT,\n",
        "                     AUG_TRANSLATION, AUG_ZOOM)\n",
        "\n",
        "model = EfficientNetB0((*IMAGE_SIZE,3), 1, aug_layer, \"imagenet\", False)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(momentum=0.9, nesterov=True), loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "augmentation_layer (Sequenti (None, 112, 112, 3)       0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
            "_________________________________________________________________\n",
            "global_avg_pool (GlobalAvera (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout_layer1 (Dropout)     (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "fc_layer (Dense)             (None, 1280)              1639680   \n",
            "_________________________________________________________________\n",
            "dropout_layer2 (Dropout)     (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 5,690,532\n",
            "Trainable params: 2,770,353\n",
            "Non-trainable params: 2,920,179\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv1cnrgQivMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa22140-1bad-4e05-94bb-d7119b83eb31"
      },
      "source": [
        "callbacks = [#CheckpointCallback(PATH_CHECKPOINT),\n",
        "             CustomLRDecay(LR_PROFILE, LR_EPOCHS),\n",
        "                          CSVLogger(PATH_CSV)]\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    steps_per_epoch = math.ceil(X_train.shape[0] / BATCH_SIZE),\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    validation_steps = math.ceil(X_test.shape[0] / BATCH_SIZE),\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=callbacks,\n",
        "                    workers=4)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.1.\n",
            "5/5 [==============================] - 16s 2s/step - loss: 0.5413 - acc: 0.6970 - val_loss: 0.2093 - val_acc: 0.9203\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.1.\n",
            "5/5 [==============================] - 3s 530ms/step - loss: 0.1476 - acc: 0.9549 - val_loss: 0.1499 - val_acc: 0.9281\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.1.\n",
            "5/5 [==============================] - 3s 530ms/step - loss: 0.0629 - acc: 0.9814 - val_loss: 0.1202 - val_acc: 0.9438\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.1.\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 0.0506 - acc: 0.9842 - val_loss: 0.0763 - val_acc: 0.9686\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.1.\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 0.0319 - acc: 0.9907 - val_loss: 0.0522 - val_acc: 0.9817\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.1.\n",
            "5/5 [==============================] - 3s 527ms/step - loss: 0.0191 - acc: 0.9934 - val_loss: 0.0419 - val_acc: 0.9817\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.1.\n",
            "5/5 [==============================] - 3s 530ms/step - loss: 0.0250 - acc: 0.9921 - val_loss: 0.0352 - val_acc: 0.9882\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.1.\n",
            "5/5 [==============================] - 3s 530ms/step - loss: 0.0212 - acc: 0.9935 - val_loss: 0.0320 - val_acc: 0.9895\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.1.\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 0.0144 - acc: 0.9956 - val_loss: 0.0286 - val_acc: 0.9922\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.1.\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 0.0079 - acc: 0.9970 - val_loss: 0.0255 - val_acc: 0.9935\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.01.\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 0.0076 - acc: 0.9972 - val_loss: 0.0243 - val_acc: 0.9948\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.01.\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 0.0157 - acc: 0.9949 - val_loss: 0.0233 - val_acc: 0.9948\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 0.01.\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0222 - val_acc: 0.9948\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 0.01.\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 0.0111 - acc: 0.9953 - val_loss: 0.0214 - val_acc: 0.9948\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 0.01.\n",
            "5/5 [==============================] - 3s 528ms/step - loss: 0.0101 - acc: 0.9966 - val_loss: 0.0205 - val_acc: 0.9948\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 0.01.\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 0.0105 - acc: 0.9961 - val_loss: 0.0195 - val_acc: 0.9948\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 0.01.\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 0.0085 - acc: 0.9978 - val_loss: 0.0187 - val_acc: 0.9948\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 0.01.\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 0.0117 - acc: 0.9945 - val_loss: 0.0179 - val_acc: 0.9948\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 0.01.\n",
            "5/5 [==============================] - 3s 531ms/step - loss: 0.0100 - acc: 0.9961 - val_loss: 0.0170 - val_acc: 0.9961\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 0.01.\n",
            "5/5 [==============================] - 3s 530ms/step - loss: 0.0058 - acc: 0.9991 - val_loss: 0.0162 - val_acc: 0.9961\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n",
            "5/5 [==============================] - 3s 528ms/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0154 - val_acc: 0.9961\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0148 - val_acc: 0.9961\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n",
            "5/5 [==============================] - 3s 531ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0142 - val_acc: 0.9961\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n",
            "5/5 [==============================] - 3s 532ms/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0137 - val_acc: 0.9961\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n",
            "5/5 [==============================] - 3s 528ms/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0132 - val_acc: 0.9961\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 0.0069 - acc: 0.9975 - val_loss: 0.0128 - val_acc: 0.9961\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n",
            "5/5 [==============================] - 3s 533ms/step - loss: 0.0085 - acc: 0.9959 - val_loss: 0.0124 - val_acc: 0.9961\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n",
            "5/5 [==============================] - 3s 530ms/step - loss: 0.0130 - acc: 0.9973 - val_loss: 0.0120 - val_acc: 0.9961\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n",
            "5/5 [==============================] - 3s 531ms/step - loss: 0.0052 - acc: 0.9973 - val_loss: 0.0117 - val_acc: 0.9961\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 0.0111 - acc: 0.9970 - val_loss: 0.0113 - val_acc: 0.9961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbO5HpO8_FfS"
      },
      "source": [
        "# EVALUATE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJdHFWJh8Lus",
        "outputId": "68e847a7-6887-421d-dbbe-584cbe402cd1"
      },
      "source": [
        "model.evaluate(X_test, y_test, batch_size=512)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 2s 801ms/step - loss: 0.0406 - acc: 0.9922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04062690585851669, 0.9921568632125854]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d08rGt7Bkqn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}